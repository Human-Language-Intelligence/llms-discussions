import json
import pandas as pd
import openai
from bert_score import score as bert_score
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
from .config import CONFIG as _CONFIG

# OpenAI API Key ì„¤ì •
client = openai.OpenAI(
    api_key=_CONFIG["openai"]["GPT.API_KEY"]
)

# âš– GPT Judge Prompt ìƒì„±
def get_judge_prompt(df, topic="NFTëŠ” ì˜ˆìˆ ì˜ ë¯¸ë˜ì¸ê°€?"):
    script_lines = []
    for i in range(0, len(df), 2):
        side1 = df.iloc[i]
        side2 = df.iloc[i + 1]
        script_lines.append(
            f'GPT: â€œ{side1["message"]}â€. GEMINI: â€œ{side2["message"]}â€'
        )
    debate_script = " ".join(script_lines)

    return f"""We had a debate and the topic was â€œ{topic}â€. The two sides in the debate each provided arguments
    to prove their side and refute the points raised by the opponent. You are a judge for this debate.
    You should be impartial and as objective as possible. The debate script will be given. You should
    give a score from 1 to 10 to each side of the debate. In your judgement, you should take into
    account the following criteria: clarity of arguments, factuality and use of evidence, rebuttal and
    counterarguments, logical consistency, persuasiveness and impact, conciseness, coherence. Also,
    you should choose the side who you think is the overall winner. Your answer MUST follow the
    following format: "GPT: [[score of GPT]], GEMINI: [[score of GEMINI]], winner: [[name of winner]]"

    The script of the debate is as follows: {debate_script}
    """

# ğŸ’¬ GPT-4o í‰ê°€ í˜¸ì¶œ
def gpt_judge(prompt):
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are a debate judge."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.3
    )
    return response.choices[0].message.content

# Coherence Flow Score (BERTScore)
def coherence_score(turns):
    scores = []
    for i in range(len(turns)):
        target = turns[i]
        others = turns[:i] + turns[i+1:]
        # ë‹¤ë¥¸ ëª¨ë“  ë°œí™”ì™€ ê°ê° ë¹„êµ í›„ í‰ê· 
        _, _, F1 = bert_score([target]*len(others), others, lang="ko", verbose=False)
        scores.append(float(F1.mean()))
    return np.mean(scores)

# Argument Diversity (Distinct-n)
def diversity_index(turns, n=2):
    vectorizer = CountVectorizer(analyzer='word', ngram_range=(n, n))
    all_ngrams = [set(ngram for ngram in vectorizer.build_analyzer()(t)) for t in turns]
    
    distinct_ratios = []
    for i, current in enumerate(all_ngrams):
        other_ngrams = set().union(*[all_ngrams[j] for j in range(len(turns)) if j != i])
        # ì–¼ë§ˆë‚˜ ë‹¤ë¥¸ n-gramìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€
        distinct = current - other_ngrams
        ratio = len(distinct) / len(current) if len(current) > 0 else 0
        distinct_ratios.append(ratio)

    return np.mean(distinct_ratios)

if __name__ == "__main__":
    # JSON íŒŒì¼ ê²½ë¡œ
    file_path = "./debate-history-1754391739291.json"

    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì •ì œ
    with open(file_path, "r", encoding="utf-8") as f:
        debate_data = json.load(f)

    df = pd.DataFrame(debate_data)
    df["timestamp"] = pd.to_datetime(df["timestamp"])
    df = df.sort_values("timestamp").reset_index(drop=True)

    # ì§ ë§ëŠ” ë°œí™”ë§Œ ì‚¬ìš© (ì§ìˆ˜ ê°œë§Œ)
    usable_df = df.iloc[:len(df) - len(df) % 2].copy()

    # GPT(GPT) / GEMINI ë¶„ë¦¬
    gpt_turns = usable_df[usable_df["role"] == "pros"]["message"].tolist()
    gemini_turns = usable_df[usable_df["role"] == "cons"]["message"].tolist()

    # í‰ê°€ ì‹¤í–‰
    prompt = get_judge_prompt(usable_df)
    judge_result = gpt_judge(prompt)

    coherence_gpt = coherence_score(gpt_turns)
    coherence_gemini = coherence_score(gemini_turns)

    diversity_gpt = diversity_index(gpt_turns)
    diversity_gemini = diversity_index(gemini_turns)

    # ê²°ê³¼ ì¶œë ¥
    print("[LLM Judge] GPT Judge í‰ê°€ ê²°ê³¼:")
    print(judge_result)
    print()
    print(f"[Coherence Flow Score] GPT: {coherence_gpt:.4f}, GEMINI: {coherence_gemini:.4f}")
    print(f"[Argument Diversity Index] GPT: {diversity_gpt:.4f}, GEMINI: {diversity_gemini:.4f}")
